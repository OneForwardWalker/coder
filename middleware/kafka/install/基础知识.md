# 性能、存储结构
	log文件存储在topic+partitionx文件夹下面；
	日志分段存储，每段1G;
	分段提升了查询效率，方便删除旧数据；
	怎么知道数据在哪个端，kafka内部维护了一个跳跃表，节点就是段号；
	段号怎么确定，按照偏移量来定义段号（代表当前段中偏移量最小的那个数据）；
	在段内定位消息采用稀疏索引 .index(偏移索引文件)，不为每条记录创建索引，而是每隔一个区间创建一个索引，在索引使用空间和查找时间中间做平衡
	.timeindex,时间索引文件，按照过期时间删除的话会用到这个索引-数据清理。
	数据清理的其他方式-log文件大小，日志起始偏移量(达到阈值之后就删除直到满足设定的阈值)。
	消息合并-多条消息存储在缓冲区，缓冲区满或者有一段时间没有生产消息的时候就会发送到broker,有点事节省网络资源，可以对批量的消息做crc校验。
	消息压缩-压缩消耗CPU，减少带宽使用，生产者和消费者都会压缩数据，压缩算法（包括版本）要保持一致（否则先解压缩再压缩，会导致性能降低）
	kafka消息写入磁盘会不会很慢，顺序写磁盘很快，甚至比随机写内存还要快
	网络优化-零拷贝技术，磁盘->内核缓冲区->网卡，减少了两次与内核的交互，大大提升了性能
	
# 稳定性
	多消费者模型-不同消费者组可以消费一个topic，使用offset机制存储那个消费者消费到了那位置；
	offset怎么存储，kafka有个_consumer_offset的topic，用来存储消费者消费到那个位置，默认50分区，3副本；
	offset里面存储了什么-value是偏移量，key是topic-partition-group的组合
	消费者提交位移的方式-自动提交，默认consumer 5s提交一次，会导致大量的无效提交，导致consumer_offset有很多重复的消息；kafka提供一种类似redis的aofrewrite的功能，叫compact策略
	consumer自动重启没来及提交会导致重复消费，需要业务保证幂等
	消费者提交的偏移量指向最老的一条没有消费的消息，是当前消费的offset+1
	消费者消息丢失-1.不关系提交结果2.保证收到leader副本的ack3.收到所有leader和follow副本的ack
	follow副本选举为leader副本;AR(所有副本)=ISR(符合选举条件的副本)+OSR(落后太多或者挂掉的副本)，从ISR中选第一个作为leader副本
# kafka顺序写磁盘快的原因：
	1.顺序写磁盘
	2.mmap(memory mapped files):将磁盘文件映射到内存，通过修改内存就能修改磁盘；问题：刷脏页的过程中重启会导致数据丢失，不可靠
	3.零拷贝
		3.1 传统io(4次拷贝)，磁盘->内核readbuffer->应用层buffer->socket buffer->NIC buffer(网卡)
		3.2 引入DMA(2次拷贝),外部设备不通过cpu而是直接与系统内存交换数据的接口技术；磁盘-dma->内核readbuffer->应用层buffer->socket buffer-dma->NIC buffer(网卡)
		3.3 mmap
		[参考](https://blog.csdn.net/yxf19034516/article/details/108518194)
		3.4 sendfile（1次拷贝）,不经过用户态，在内核态做一次拷贝，磁盘-dma->内核readbuffer->socket buffer-dma->NIC buffer(网卡)
		3.5 sendfile(DMA收集拷贝)(零拷贝)，数据->read buffer->NIC；DMA直接读取的read buffer
		
		3.6 kafka实现零拷贝，kafka是scala和java实现的，java sendfile是通过NIO的FileChannel的transferTo和transferFrom方法实现的零拷贝
# kafka顺序写磁盘快的原因：
	1.顺序写磁盘
	2.mmap(memory mapped files):将磁盘文件映射到内存，通过修改内存就能修改磁盘；问题：刷脏页的过程中重启会导致数据丢失，不可靠
	3.零拷贝
		3.1 传统io(4次拷贝)，磁盘->内核readbuffer->应用层buffer->socket buffer->NIC buffer(网卡)
		3.2 引入DMA(2次拷贝),外部设备不通过cpu而是直接与系统内存交换数据的接口技术；磁盘-dma->内核readbuffer->应用层buffer->socket buffer-dma->NIC buffer(网卡)
		3.3 sendfile（1次拷贝）,不经过用户态，在内核态做一次拷贝，磁盘-dma->内核readbuffer->socket buffer-dma->NIC buffer(网卡)
		3.4 sendfile(DMA收集拷贝)(零拷贝)，数据->read buffer->NIC；DMA直接读取的read buffer
		
		3.5 kafka实现零拷贝，kafka是scala和java实现的，java sendfile是通过NIO的FileChannel的transferTo和transferFrom方法实现的零拷贝
		
# acks对消息持久化的影响
	1.acks参数：
		acks=0:生产者发送完消息就认为成功，消息可能会丢失
		acks=1（kafka默认）:leader的收到消息后,并且写入磁盘就认为写成功
		acks=all: ISR列表里面的副本全部收到消息就认为写成功
		
		acks=all也不一定可以保证消息不丢失，ISR列表里面至少有2个副本才行，起码有一个leader和一个follower
		
# 消息丢失怎么处理
	1.消费者消息丢失：手动提交offset，消费实现幂等
	2.生产者消息丢失：
		2.1 重试，配置retries=3；send函数挂回调
	3.broker消息丢失（设置冗余副本的个数，设置ISR的大小，保证acks=all的时候写入尽可能多的副本里去）：
		acks=all:数据写到所有ISR中的副本
		relication.factor >= 3：设置topic的冗余副本
		min.insync.relicas > 1:设置最小保持同步的副本； replication.factor = min.insync.replicas + 1保证高可用。
# 如何保证顺序消费(key是一样的，就会存储到同一个partition)
## 一个topic，一个partition
##
1. 一个topic，指定partition，消费者单线程消费
2. 一个topic，多个partiton,消费者是单线程的，一般会开多线程去消费任务，这个可以吧每个key分开放到队列里面，多key并行消费
